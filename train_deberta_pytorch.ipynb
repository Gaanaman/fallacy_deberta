{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DeBERTa V2 Training with Focal Loss\n",
                "\n",
                "**Purpose**: Fine-tune DeBERTa V2 XLarge using PyTorch for logical fallacy detection\n",
                "\n",
                "**Dataset**: FLICC (Fallacy detection dataset with train/val/test splits)\n",
                "\n",
                "**Method**: Full fine-tuning with Focal Loss (Gamma=4)\n",
                "\n",
                "---\n",
                "\n",
                "## Configuration Overview\n",
                "\n",
                "Based on paper's findings:\n",
                "- **Model**: microsoft/deberta-v2-xlarge\n",
                "- **Learning Rate**: 1e-5 (paper-optimal)\n",
                "- **Focal Loss Gamma**: 4.0 (critical for performance)\n",
                "- **Weight Decay**: 0.01\n",
                "- **Epochs**: 15\n",
                "- **Batch Size**: 4 (with gradient accumulation of 4 = effective batch 16)\n",
                "- **Device**: Apple Silicon MPS (Metal Performance Shaders)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Core PyTorch\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# HuggingFace Transformers\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    Trainer,\n",
                "    TrainingArguments,\n",
                "    DataCollatorWithPadding,\n",
                "    EarlyStoppingCallback\n",
                ")\n",
                "\n",
                "# Data handling\n",
                "from datasets import Dataset, DatasetDict\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Metrics\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score,\n",
                "    precision_recall_fscore_support,\n",
                "    classification_report,\n",
                "    confusion_matrix\n",
                ")\n",
                "\n",
                "# Utilities\n",
                "import json\n",
                "from pathlib import Path\n",
                "from dataclasses import dataclass\n",
                "from typing import Dict, List, Optional\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"All libraries imported successfully!\")\n",
                "\n",
                "# Check device availability\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "    print(f\"Using Apple Silicon GPU (MPS)\")\n",
                "elif torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "    print(f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "    print(\"Using CPU\")\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Training Configuration\n",
                "\n",
                "### Paper-Validated Parameters\n",
                "\n",
                "Based on research findings:\n",
                "- **Focal Loss Gamma 4.0**: Critical for handling class imbalance\n",
                "- **Learning Rate 1e-5**: Validated as optimal\n",
                "- **15 Epochs**: Full convergence duration\n",
                "- **Weight Decay 0.01**: Standard regularization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class TrainingConfig:\n",
                "    \"\"\"\n",
                "    Training configuration based on paper's best parameters.\n",
                "    \"\"\"\n",
                "    \n",
                "    # Model Configuration\n",
                "    model_name: str = \"microsoft/deberta-v2-xlarge\"\n",
                "    \n",
                "    # Training Hyperparameters (Paper's Best)\n",
                "    learning_rate: float = 1.0e-5        # Paper-validated optimal\n",
                "    weight_decay: float = 0.01           # Standard regularization\n",
                "    num_epochs: int = 15                 # Full convergence\n",
                "    batch_size: int = 4                  # Small for stability\n",
                "    gradient_accumulation_steps: int = 4 # Effective batch = 16\n",
                "    \n",
                "    # Focal Loss Configuration\n",
                "    focal_gamma: float = 4.0             # Critical parameter (paper finding)\n",
                "    \n",
                "    # Data Paths\n",
                "    train_data_path: str = \"Data/fallacy_train.csv\"\n",
                "    val_data_path: str = \"Data/fallacy_val.csv\"\n",
                "    test_data_path: str = \"Data/fallacy_test.csv\"\n",
                "    \n",
                "    # Output Configuration\n",
                "    output_dir: str = \"./output/deberta_flicc\"\n",
                "    \n",
                "    # Training Options\n",
                "    max_seq_length: int = 512            # Maximum sequence length\n",
                "    warmup_ratio: float = 0.1            # 10% warmup\n",
                "    seed: int = 42                       # Random seed\n",
                "    logging_steps: int = 10              # Log every N steps\n",
                "    save_strategy: str = \"epoch\"         # Save after each epoch\n",
                "    evaluation_strategy: str = \"epoch\"   # Evaluate after each epoch\n",
                "    \n",
                "    # Early Stopping\n",
                "    early_stopping_patience: int = 3     # Stop if no improvement for 3 epochs\n",
                "    metric_for_best_model: str = \"f1\"    # Use F1 score for best model\n",
                "    \n",
                "\n",
                "# Initialize configuration\n",
                "config = TrainingConfig()\n",
                "\n",
                "# Display configuration\n",
                "print(\"=\"*70)\n",
                "print(\"TRAINING CONFIGURATION (Paper Parameters)\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nModel: {config.model_name}\")\n",
                "\n",
                "print(f\"\\nTraining Hyperparameters:\")\n",
                "print(f\"  Learning Rate: {config.learning_rate} (paper-optimal)\")\n",
                "print(f\"  Weight Decay: {config.weight_decay}\")\n",
                "print(f\"  Epochs: {config.num_epochs}\")\n",
                "print(f\"  Batch Size: {config.batch_size}\")\n",
                "print(f\"  Gradient Accumulation: {config.gradient_accumulation_steps}\")\n",
                "print(f\"  Effective Batch Size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
                "\n",
                "print(f\"\\nFocal Loss Configuration:\")\n",
                "print(f\"  Gamma: {config.focal_gamma} (critical for performance)\")\n",
                "\n",
                "print(f\"\\nData Splits:\")\n",
                "print(f\"  Training: {config.train_data_path}\")\n",
                "print(f\"  Validation: {config.val_data_path}\")\n",
                "print(f\"  Test: {config.test_data_path}\")\n",
                "\n",
                "print(f\"\\nOutput Directory: {config.output_dir}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load Data\n",
                "\n",
                "Load all three data splits and prepare label mappings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(file_path: str, split_name: str) -> pd.DataFrame:\n",
                "    \"\"\"\n",
                "    Load fallacy detection dataset.\n",
                "    \n",
                "    Args:\n",
                "        file_path: Path to CSV file\n",
                "        split_name: Name of split for display\n",
                "        \n",
                "    Returns:\n",
                "        DataFrame with text and label columns\n",
                "    \"\"\"\n",
                "    print(f\"\\nLoading {split_name} data from: {file_path}\")\n",
                "    df = pd.read_csv(file_path)\n",
                "    print(f\"Loaded {len(df):,} examples\")\n",
                "    \n",
                "    # Display label distribution\n",
                "    print(f\"\\nLabel distribution:\")\n",
                "    for label, count in df['label'].value_counts().sort_index().items():\n",
                "        print(f\"  {label:25s}: {count:4d} ({count/len(df)*100:.1f}%)\")\n",
                "    \n",
                "    return df\n",
                "\n",
                "\n",
                "# Load all splits\n",
                "print(\"=\"*70)\n",
                "print(\"LOADING DATA SPLITS\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "train_df = load_data(config.train_data_path, \"TRAIN\")\n",
                "val_df = load_data(config.val_data_path, \"VALIDATION\")\n",
                "test_df = load_data(config.test_data_path, \"TEST\")\n",
                "\n",
                "# Create label mappings\n",
                "unique_labels = sorted(train_df['label'].unique().tolist())\n",
                "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
                "id2label = {idx: label for label, idx in label2id.items()}\n",
                "\n",
                "print(f\"\\n\" + \"=\"*70)\n",
                "print(\"LABEL MAPPINGS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nNumber of classes: {len(unique_labels)}\")\n",
                "print(f\"\\nLabel to ID mapping:\")\n",
                "for label, idx in sorted(label2id.items()):\n",
                "    print(f\"  {idx}: {label}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Prepare Datasets for HuggingFace\n",
                "\n",
                "Convert pandas DataFrames to HuggingFace Datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def prepare_dataset(df: pd.DataFrame) -> Dataset:\n",
                "    \"\"\"\n",
                "    Convert DataFrame to HuggingFace Dataset.\n",
                "    \n",
                "    Args:\n",
                "        df: DataFrame with text and label columns\n",
                "        \n",
                "    Returns:\n",
                "        HuggingFace Dataset\n",
                "    \"\"\"\n",
                "    # Add numeric labels\n",
                "    df['labels'] = df['label'].map(label2id)\n",
                "    \n",
                "    # Create HuggingFace dataset\n",
                "    dataset = Dataset.from_pandas(df[['text', 'labels']])\n",
                "    \n",
                "    return dataset\n",
                "\n",
                "\n",
                "# Create datasets\n",
                "print(\"\\nCreating HuggingFace datasets...\")\n",
                "\n",
                "train_dataset = prepare_dataset(train_df)\n",
                "val_dataset = prepare_dataset(val_df)\n",
                "test_dataset = prepare_dataset(test_df)\n",
                "\n",
                "# Create DatasetDict\n",
                "dataset_dict = DatasetDict({\n",
                "    'train': train_dataset,\n",
                "    'validation': val_dataset,\n",
                "    'test': test_dataset\n",
                "})\n",
                "\n",
                "print(\"\\nDataset creation complete!\")\n",
                "print(dataset_dict)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Load Tokenizer and Tokenize Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"\\nLoading tokenizer: {config.model_name}\")\n",
                "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
                "print(\"Tokenizer loaded!\")\n",
                "\n",
                "\n",
                "def tokenize_function(examples):\n",
                "    \"\"\"\n",
                "    Tokenize text examples.\n",
                "    \n",
                "    Args:\n",
                "        examples: Batch of examples with 'text' field\n",
                "        \n",
                "    Returns:\n",
                "        Tokenized examples\n",
                "    \"\"\"\n",
                "    return tokenizer(\n",
                "        examples['text'],\n",
                "        truncation=True,\n",
                "        max_length=config.max_seq_length,\n",
                "        padding=False  # Dynamic padding handled by data collator\n",
                "    )\n",
                "\n",
                "\n",
                "print(\"\\nTokenizing datasets...\")\n",
                "tokenized_datasets = dataset_dict.map(\n",
                "    tokenize_function,\n",
                "    batched=True,\n",
                "    desc=\"Tokenizing\"\n",
                ")\n",
                "\n",
                "print(\"\\nTokenization complete!\")\n",
                "print(tokenized_datasets)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"\\nLoading model: {config.model_name}\")\n",
                "print(\"This may take several minutes...\\n\")\n",
                "\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    config.model_name,\n",
                "    num_labels=len(unique_labels),\n",
                "    id2label=id2label,\n",
                "    label2id=label2id,\n",
                "    problem_type=\"single_label_classification\"\n",
                ")\n",
                "\n",
                "# Move model to device\n",
                "model = model.to(device)\n",
                "\n",
                "print(\"Model loaded successfully!\")\n",
                "print(f\"\\nModel parameters: {model.num_parameters():,}\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Define Focal Loss Trainer\n",
                "\n",
                "Custom trainer implementing Focal Loss with Gamma=4.\n",
                "\n",
                "**Focal Loss**: Addresses class imbalance by down-weighting easy examples.\n",
                "\n",
                "Formula: `FL(pt) = -(1 - pt)^γ * log(pt)`\n",
                "\n",
                "Where:\n",
                "- `pt` is the probability of the correct class\n",
                "- `γ` (gamma) controls the down-weighting factor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FocalLossTrainer(Trainer):\n",
                "    \"\"\"\n",
                "    Custom Trainer with Focal Loss.\n",
                "    \n",
                "    Implements focal loss to handle class imbalance as per paper's findings.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, focal_gamma: float = 4.0, *args, **kwargs):\n",
                "        super().__init__(*args, **kwargs)\n",
                "        self.focal_gamma = focal_gamma\n",
                "        print(f\"\\nUsing Focal Loss with Gamma = {self.focal_gamma}\")\n",
                "    \n",
                "    def compute_loss(self, model, inputs, return_outputs=False):\n",
                "        \"\"\"\n",
                "        Compute focal loss instead of standard cross-entropy.\n",
                "        \n",
                "        Args:\n",
                "            model: The model being trained\n",
                "            inputs: Input batch\n",
                "            return_outputs: Whether to return model outputs\n",
                "            \n",
                "        Returns:\n",
                "            Loss value (and outputs if requested)\n",
                "        \"\"\"\n",
                "        labels = inputs.pop(\"labels\")\n",
                "        \n",
                "        # Forward pass\n",
                "        outputs = model(**inputs)\n",
                "        logits = outputs.logits\n",
                "        \n",
                "        # Compute focal loss\n",
                "        ce_loss = F.cross_entropy(logits, labels, reduction='none')\n",
                "        pt = torch.exp(-ce_loss)  # Probability of true class\n",
                "        focal_loss = ((1 - pt) ** self.focal_gamma * ce_loss).mean()\n",
                "        \n",
                "        return (focal_loss, outputs) if return_outputs else focal_loss\n",
                "\n",
                "\n",
                "print(\"Focal Loss Trainer defined!\")\n",
                "print(f\"Gamma parameter: {config.focal_gamma}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Define Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_metrics(eval_pred):\n",
                "    \"\"\"\n",
                "    Compute evaluation metrics.\n",
                "    \n",
                "    Args:\n",
                "        eval_pred: Tuple of (predictions, labels)\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary of metrics\n",
                "    \"\"\"\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy = accuracy_score(labels, predictions)\n",
                "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
                "        labels, \n",
                "        predictions, \n",
                "        average='weighted',\n",
                "        zero_division=0\n",
                "    )\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'f1': f1\n",
                "    }\n",
                "\n",
                "\n",
                "print(\"Metrics function defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Setup Training Arguments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create output directory\n",
                "Path(config.output_dir).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Define training arguments\n",
                "training_args = TrainingArguments(\n",
                "    # Output\n",
                "    output_dir=config.output_dir,\n",
                "    \n",
                "    # Training hyperparameters\n",
                "    learning_rate=config.learning_rate,\n",
                "    weight_decay=config.weight_decay,\n",
                "    num_train_epochs=config.num_epochs,\n",
                "    per_device_train_batch_size=config.batch_size,\n",
                "    per_device_eval_batch_size=config.batch_size,\n",
                "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
                "    \n",
                "    # Learning rate schedule\n",
                "    warmup_ratio=config.warmup_ratio,\n",
                "    lr_scheduler_type=\"linear\",\n",
                "    \n",
                "    # Evaluation and saving\n",
                "    evaluation_strategy=config.evaluation_strategy,\n",
                "    save_strategy=config.save_strategy,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=config.metric_for_best_model,\n",
                "    greater_is_better=True,\n",
                "    \n",
                "    # Logging\n",
                "    logging_dir=f\"{config.output_dir}/logs\",\n",
                "    logging_steps=config.logging_steps,\n",
                "    report_to=[\"tensorboard\"],\n",
                "    \n",
                "    # Device configuration\n",
                "    use_mps_device=(device.type == \"mps\"),\n",
                "    \n",
                "    # Reproducibility\n",
                "    seed=config.seed,\n",
                "    \n",
                "    # Memory optimization\n",
                "    fp16=False,  # MPS works better with FP32\n",
                "    gradient_checkpointing=False,  # Can enable if OOM\n",
                "    \n",
                "    # Save settings\n",
                "    save_total_limit=3,  # Keep only 3 best checkpoints\n",
                ")\n",
                "\n",
                "# Display training configuration\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TRAINING ARGUMENTS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nOutput directory: {training_args.output_dir}\")\n",
                "print(f\"\\nTraining:\")\n",
                "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
                "print(f\"  Batch size (per device): {training_args.per_device_train_batch_size}\")\n",
                "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
                "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
                "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
                "print(f\"  Weight decay: {training_args.weight_decay}\")\n",
                "print(f\"  Warmup ratio: {training_args.warmup_ratio}\")\n",
                "print(f\"\\nEvaluation:\")\n",
                "print(f\"  Strategy: {training_args.evaluation_strategy}\")\n",
                "print(f\"  Metric for best model: {training_args.metric_for_best_model}\")\n",
                "print(f\"\\nDevice: {device}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Initialize Trainer and Start Training\n",
                "\n",
                "**Expected Duration**: Full fine-tuning of DeBERTa V2 XLarge for 15 epochs will take many hours (potentially 10-20 hours on Apple Silicon).\n",
                "\n",
                "The model will be evaluated after each epoch and the best model will be saved based on F1 score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data collator for dynamic padding\n",
                "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
                "\n",
                "# Initialize trainer\n",
                "trainer = FocalLossTrainer(\n",
                "    focal_gamma=config.focal_gamma,\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_datasets['train'],\n",
                "    eval_dataset=tokenized_datasets['validation'],\n",
                "    tokenizer=tokenizer,\n",
                "    data_collator=data_collator,\n",
                "    compute_metrics=compute_metrics,\n",
                "    callbacks=[EarlyStoppingCallback(early_stopping_patience=config.early_stopping_patience)]\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STARTING TRAINING\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nModel: {config.model_name}\")\n",
                "print(f\"Training samples: {len(tokenized_datasets['train']):,}\")\n",
                "print(f\"Validation samples: {len(tokenized_datasets['validation']):,}\")\n",
                "print(f\"\\nThis will take many hours. Monitor the progress below.\")\n",
                "print(f\"\\nTensorBoard logs: {config.output_dir}/logs\")\n",
                "print(f\"To view: tensorboard --logdir {config.output_dir}/logs\")\n",
                "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
                "\n",
                "# Start training\n",
                "train_result = trainer.train()\n",
                "\n",
                "# Save the final model\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TRAINING COMPLETE\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nSaving final model to: {config.output_dir}/final_model\")\n",
                "trainer.save_model(f\"{config.output_dir}/final_model\")\n",
                "tokenizer.save_pretrained(f\"{config.output_dir}/final_model\")\n",
                "print(\"Model saved!\")\n",
                "\n",
                "# Display training metrics\n",
                "print(\"\\nTraining Metrics:\")\n",
                "print(f\"  Training Loss: {train_result.training_loss:.4f}\")\n",
                "print(f\"  Training Steps: {train_result.global_step}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: Validation Set Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"VALIDATION SET EVALUATION\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Evaluate on validation set\n",
                "val_results = trainer.evaluate(eval_dataset=tokenized_datasets['validation'])\n",
                "\n",
                "print(\"\\nValidation Results:\")\n",
                "for key, value in val_results.items():\n",
                "    if isinstance(value, float):\n",
                "        print(f\"  {key}: {value:.4f}\")\n",
                "    else:\n",
                "        print(f\"  {key}: {value}\")\n",
                "\n",
                "# Get predictions for detailed analysis\n",
                "val_predictions = trainer.predict(tokenized_datasets['validation'])\n",
                "val_preds = np.argmax(val_predictions.predictions, axis=1)\n",
                "val_labels = val_predictions.label_ids\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nDetailed Classification Report (Validation):\")\n",
                "print(classification_report(\n",
                "    val_labels,\n",
                "    val_preds,\n",
                "    target_names=[id2label[i] for i in range(len(id2label))],\n",
                "    zero_division=0\n",
                "))\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 12: Test Set Evaluation (Final Performance)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TEST SET EVALUATION (Final Performance)\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Evaluate on test set\n",
                "test_results = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
                "\n",
                "print(\"\\nTest Results:\")\n",
                "for key, value in test_results.items():\n",
                "    if isinstance(value, float):\n",
                "        print(f\"  {key}: {value:.4f}\")\n",
                "    else:\n",
                "        print(f\"  {key}: {value}\")\n",
                "\n",
                "# Get predictions for detailed analysis\n",
                "test_predictions = trainer.predict(tokenized_datasets['test'])\n",
                "test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
                "test_labels = test_predictions.label_ids\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nDetailed Classification Report (Test):\")\n",
                "print(classification_report(\n",
                "    test_labels,\n",
                "    test_preds,\n",
                "    target_names=[id2label[i] for i in range(len(id2label))],\n",
                "    zero_division=0\n",
                "))\n",
                "\n",
                "# Confusion matrix\n",
                "print(\"\\nConfusion Matrix (Test):\")\n",
                "cm = confusion_matrix(test_labels, test_preds)\n",
                "print(cm)\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 13: Save Training Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive training report\n",
                "training_report = {\n",
                "    \"model_configuration\": {\n",
                "        \"model_name\": config.model_name,\n",
                "        \"num_parameters\": model.num_parameters(),\n",
                "        \"num_labels\": len(unique_labels),\n",
                "        \"labels\": unique_labels\n",
                "    },\n",
                "    \"training_configuration\": {\n",
                "        \"learning_rate\": config.learning_rate,\n",
                "        \"weight_decay\": config.weight_decay,\n",
                "        \"num_epochs\": config.num_epochs,\n",
                "        \"batch_size\": config.batch_size,\n",
                "        \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n",
                "        \"effective_batch_size\": config.batch_size * config.gradient_accumulation_steps,\n",
                "        \"focal_gamma\": config.focal_gamma,\n",
                "        \"max_seq_length\": config.max_seq_length,\n",
                "        \"warmup_ratio\": config.warmup_ratio,\n",
                "        \"seed\": config.seed\n",
                "    },\n",
                "    \"data_splits\": {\n",
                "        \"train_samples\": len(train_df),\n",
                "        \"validation_samples\": len(val_df),\n",
                "        \"test_samples\": len(test_df)\n",
                "    },\n",
                "    \"training_results\": {\n",
                "        \"training_loss\": float(train_result.training_loss),\n",
                "        \"total_steps\": int(train_result.global_step)\n",
                "    },\n",
                "    \"validation_results\": {\n",
                "        key: float(value) if isinstance(value, (int, float)) else value \n",
                "        for key, value in val_results.items()\n",
                "    },\n",
                "    \"test_results\": {\n",
                "        key: float(value) if isinstance(value, (int, float)) else value \n",
                "        for key, value in test_results.items()\n",
                "    },\n",
                "    \"label_mappings\": {\n",
                "        \"label2id\": label2id,\n",
                "        \"id2label\": id2label\n",
                "    }\n",
                "}\n",
                "\n",
                "# Save report\n",
                "report_path = Path(config.output_dir) / \"training_report.json\"\n",
                "with open(report_path, \"w\") as f:\n",
                "    json.dump(training_report, f, indent=2)\n",
                "\n",
                "print(f\"\\nTraining report saved to: {report_path}\")\n",
                "\n",
                "# Display summary\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TRAINING SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "print(json.dumps(training_report, indent=2))\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Complete!\n",
                "\n",
                "### Summary\n",
                "\n",
                "DeBERTa V2 XLarge has been successfully fine-tuned with Focal Loss (Gamma=4) for fallacy detection.\n",
                "\n",
                "### Output Files\n",
                "\n",
                "Located in `./output/deberta_flicc/`:\n",
                "- `final_model/` - Fine-tuned model and tokenizer\n",
                "- `training_report.json` - Complete training report\n",
                "- `logs/` - TensorBoard logs\n",
                "- Checkpoint directories for best models\n",
                "\n",
                "### Performance Metrics\n",
                "\n",
                "- **Validation Results**: See Step 11\n",
                "- **Test Results**: See Step 12 (final unbiased performance)\n",
                "\n",
                "### Usage Example\n",
                "\n",
                "```python\n",
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "import torch\n",
                "\n",
                "# Load fine-tuned model\n",
                "model_path = \"./output/deberta_flicc/final_model\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
                "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
                "\n",
                "# Prepare text\n",
                "text = \"Your text here\"\n",
                "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
                "\n",
                "# Get prediction\n",
                "with torch.no_grad():\n",
                "    outputs = model(**inputs)\n",
                "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
                "    predicted_class = torch.argmax(predictions, dim=-1).item()\n",
                "\n",
                "print(f\"Predicted fallacy: {id2label[predicted_class]}\")\n",
                "```\n",
                "\n",
                "### Monitoring Training\n",
                "\n",
                "To view training progress in TensorBoard:\n",
                "```bash\n",
                "tensorboard --logdir ./output/deberta_flicc/logs\n",
                "```\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "1. Analyze confusion matrix to identify challenging fallacy pairs\n",
                "2. Review misclassified examples\n",
                "3. Compare with LoRA-based Qwen model performance\n",
                "4. Deploy the best performing model"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}