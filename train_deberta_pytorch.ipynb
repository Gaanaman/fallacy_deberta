{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DeBERTa V2 Training with Focal Loss\n",
                "\n",
                "**Purpose**: Fine-tune DeBERTa V2 XLarge using PyTorch for logical fallacy detection\n",
                "\n",
                "**Dataset**: FLICC (Fallacy detection dataset with train/val/test splits)\n",
                "\n",
                "**Method**: Full fine-tuning with Focal Loss (Gamma=4)\n",
                "\n",
                "---\n",
                "\n",
                "## Configuration Overview\n",
                "\n",
                "Based on paper's findings:\n",
                "- **Model**: microsoft/deberta-v2-xlarge\n",
                "- **Learning Rate**: 1e-5 (paper-optimal)\n",
                "- **Focal Loss Gamma**: 4.0 (critical for performance)\n",
                "- **Weight Decay**: 0.01\n",
                "- **Epochs**: 15\n",
                "- **Batch Size**: 1 (with gradient accumulation of 4 = effective batch 16)\n",
                "- **Device**: Apple Silicon MPS (Metal Performance Shaders)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Import Required Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "All libraries imported successfully!\n",
                        "Using Apple Silicon GPU (MPS)\n",
                        "PyTorch version: 2.9.1\n"
                    ]
                }
            ],
            "source": [
                "# Import libraries\n",
                "import os\n",
                "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
                "\n",
                "# Core PyTorch\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# HuggingFace Transformers\n",
                "from transformers import (\n",
                "    AutoTokenizer,\n",
                "    AutoModelForSequenceClassification,\n",
                "    Trainer,\n",
                "    TrainingArguments,\n",
                "    DataCollatorWithPadding,\n",
                "    EarlyStoppingCallback\n",
                ")\n",
                "\n",
                "# Data handling\n",
                "from datasets import Dataset, DatasetDict, load_dataset\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from transformers import DebertaV2Tokenizer\n",
                "\n",
                "# Metrics\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score,\n",
                "    precision_recall_fscore_support,\n",
                "    classification_report,\n",
                "    confusion_matrix,\n",
                "    ConfusionMatrixDisplay\n",
                ")\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Utilities\n",
                "import json\n",
                "from pathlib import Path\n",
                "from dataclasses import dataclass\n",
                "from typing import Dict, List, Optional\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"All libraries imported successfully!\")\n",
                "\n",
                "# Check device availability\n",
                "if torch.backends.mps.is_available():\n",
                "    device = torch.device(\"mps\")\n",
                "    print(f\"Using Apple Silicon GPU (MPS)\")\n",
                "elif torch.cuda.is_available():\n",
                "    device = torch.device(\"cuda\")\n",
                "    print(f\"Using CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
                "else:\n",
                "    device = torch.device(\"cpu\")\n",
                "    print(\"Using CPU\")\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Training Configuration\n",
                "\n",
                "### Paper-Validated Parameters\n",
                "\n",
                "Based on research findings:\n",
                "- **Focal Loss Gamma 4.0**: Critical for handling class imbalance\n",
                "- **Learning Rate 1e-5**: Validated as optimal\n",
                "- **15 Epochs**: Full convergence duration\n",
                "- **Weight Decay 0.01**: Standard regularization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "======================================================================\n",
                        "TRAINING CONFIGURATION (Paper Parameters)\n",
                        "======================================================================\n",
                        "\n",
                        "Model: microsoft/deberta-v2-xlarge\n",
                        "\n",
                        "Training Hyperparameters:\n",
                        "  Learning Rate: 1e-05 (paper-optimal)\n",
                        "  Weight Decay: 0.01\n",
                        "  Epochs: 15\n",
                        "  Batch Size: 1\n",
                        "  Gradient Accumulation: 16\n",
                        "  Effective Batch Size: 16\n",
                        "\n",
                        "Focal Loss Configuration:\n",
                        "  Gamma: 4 (critical for performance)\n",
                        "\n",
                        "Data Splits:\n",
                        "  Training: Data/fallacy_train.csv\n",
                        "  Validation: Data/fallacy_val.csv\n",
                        "  Test: Data/fallacy_test.csv\n",
                        "\n",
                        "Output Directory: ./output/deberta_flicc\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "@dataclass\n",
                "class TrainingConfig:\n",
                "    \"\"\"\n",
                "    Training configuration based on paper's best parameters.\n",
                "    \"\"\"\n",
                "    \n",
                "    # Model Configuration\n",
                "    model_name: str = \"microsoft/deberta-v2-xlarge\"\n",
                "    \n",
                "    # Training Hyperparameters (Paper's Best)\n",
                "    learning_rate: float = 1.0e-5        # Paper-validated optimal\n",
                "    weight_decay: float = 0.01           # Standard regularization\n",
                "    num_epochs: int = 15                 # Full convergence : Tuned to 5 for Mac M1 Max!\n",
                "    batch_size: int = 1                  # Small for stability\n",
                "    gradient_accumulation_steps: int = 16 # Effective batch = 16\n",
                "    \n",
                "    # Focal Loss Configuration\n",
                "    focal_gamma: float = 4.0             # Critical parameter (paper finding)\n",
                "    \n",
                "    # Data Paths\n",
                "    train_data_path: str = \"Data/fallacy_train.csv\"\n",
                "    val_data_path: str = \"Data/fallacy_val.csv\"\n",
                "    test_data_path: str = \"Data/fallacy_test.csv\"\n",
                "    \n",
                "    # Output Configuration\n",
                "    output_dir: str = \"./output/deberta_flicc\"\n",
                "    \n",
                "    # Training Options\n",
                "    max_seq_length: int = 512            # Maximum sequence length\n",
                "    warmup_ratio: float = 0.1            # 10% warmup\n",
                "    seed: int = 42                       # Random seed\n",
                "    logging_steps: int = 10              # Log every N steps\n",
                "    save_strategy: str = \"epoch\"         # Save after each epoch\n",
                "    evaluation_strategy: str = \"epoch\"   # Evaluate after each epoch\n",
                "    \n",
                "    # Early Stopping\n",
                "    early_stopping_patience: int = 3     # Stop if no improvement for 3 epochs\n",
                "    metric_for_best_model: str = \"f1\"    # Use F1 score for best model\n",
                "    \n",
                "\n",
                "# Initialize configuration\n",
                "config = TrainingConfig()\n",
                "\n",
                "# Display configuration\n",
                "print(\"=\"*70)\n",
                "print(\"TRAINING CONFIGURATION (Paper Parameters)\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nModel: {config.model_name}\")\n",
                "\n",
                "print(f\"\\nTraining Hyperparameters:\")\n",
                "print(f\"  Learning Rate: {config.learning_rate} (paper-optimal)\")\n",
                "print(f\"  Weight Decay: {config.weight_decay}\")\n",
                "print(f\"  Epochs: {config.num_epochs}\")\n",
                "print(f\"  Batch Size: {config.batch_size}\")\n",
                "print(f\"  Gradient Accumulation: {config.gradient_accumulation_steps}\")\n",
                "print(f\"  Effective Batch Size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
                "\n",
                "print(f\"\\nFocal Loss Configuration:\")\n",
                "print(f\"  Gamma: {config.focal_gamma} (critical for performance)\")\n",
                "\n",
                "print(f\"\\nData Splits:\")\n",
                "print(f\"  Training: {config.train_data_path}\")\n",
                "print(f\"  Validation: {config.val_data_path}\")\n",
                "print(f\"  Test: {config.test_data_path}\")\n",
                "\n",
                "print(f\"\\nOutput Directory: {config.output_dir}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Load Data\n",
                "\n",
                "Load all three data splits and prepare label mappings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "======================================================================\n",
                        "LOADING DATA (Memory-Efficient Mode)\n",
                        "======================================================================\n",
                        "\n",
                        "Loading datasets from CSV files...\n",
                        "Mapping labels...\n",
                        "\n",
                        "======================================================================\n",
                        "DATA LOADING SUMMARY\n",
                        "======================================================================\n",
                        "\n",
                        "Training samples:   1,796\n",
                        "Validation samples: 457\n",
                        "Test samples:       256\n",
                        "\n",
                        "Number of classes: 12\n",
                        "\n",
                        "Label to ID mapping:\n",
                        "  0: ad hominem\n",
                        "  1: anecdote\n",
                        "  2: cherry picking\n",
                        "  3: conspiracy theory\n",
                        "  4: fake experts\n",
                        "  5: false choice\n",
                        "  6: false equivalence\n",
                        "  7: impossible expectations\n",
                        "  8: misrepresentation\n",
                        "  9: oversimplification\n",
                        "  10: single cause\n",
                        "  11: slothful induction\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Load datasets using memory-efficient method (zero-copy)\n",
                "print(\"=\"*70)\n",
                "print(\"LOADING DATA (Memory-Efficient Mode)\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "data_files = {\n",
                "    \"train\": config.train_data_path,\n",
                "    \"validation\": config.val_data_path,\n",
                "    \"test\": config.test_data_path\n",
                "}\n",
                "\n",
                "print(\"\\nLoading datasets from CSV files...\")\n",
                "dataset_dict = load_dataset(\"csv\", data_files=data_files)\n",
                "\n",
                "# Get unique labels from training set\n",
                "unique_labels = sorted(list(set(dataset_dict[\"train\"][\"label\"])))\n",
                "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
                "id2label = {idx: label for label, idx in label2id.items()}\n",
                "\n",
                "# Map labels to IDs\n",
                "def map_labels(example):\n",
                "    example[\"labels\"] = label2id[example[\"label\"]]\n",
                "    return example\n",
                "\n",
                "print(\"Mapping labels...\")\n",
                "dataset_dict = dataset_dict.map(map_labels)\n",
                "\n",
                "# Display info\n",
                "print(f\"\\n\" + \"=\"*70)\n",
                "print(\"DATA LOADING SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nTraining samples:   {len(dataset_dict['train']):,}\")\n",
                "print(f\"Validation samples: {len(dataset_dict['validation']):,}\")\n",
                "print(f\"Test samples:       {len(dataset_dict['test']):,}\")\n",
                "print(f\"\\nNumber of classes: {len(unique_labels)}\")\n",
                "print(f\"\\nLabel to ID mapping:\")\n",
                "for label, idx in sorted(label2id.items(), key=lambda x: x[1]):\n",
                "    print(f\"  {idx}: {label}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Load Tokenizer and Tokenize Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Loading tokenizer: microsoft/deberta-v2-xlarge\n",
                        "Tokenizer loaded!\n",
                        "\n",
                        "Tokenizing datasets...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a8a0ea0645c945be8e28ca3b62744962",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Tokenizing:   0%|          | 0/1796 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "42c424f09274433697f88837bebb2961",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Tokenizing:   0%|          | 0/457 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2ed029bba5bd4d5ab9f006ea99e67e0f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Tokenizing:   0%|          | 0/256 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Tokenization complete!\n",
                        "\n",
                        "Columns kept for training: ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n",
                        "DatasetDict({\n",
                        "    train: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 1796\n",
                        "    })\n",
                        "    validation: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 457\n",
                        "    })\n",
                        "    test: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 256\n",
                        "    })\n",
                        "})\n"
                    ]
                }
            ],
            "source": [
                "print(f\"\\nLoading tokenizer: {config.model_name}\")\n",
                "tokenizer = DebertaV2Tokenizer.from_pretrained(config.model_name)\n",
                "print(\"Tokenizer loaded!\")\n",
                "\n",
                "\n",
                "def tokenize_function(examples):\n",
                "    \"\"\"\n",
                "    Tokenize text examples.\n",
                "    \n",
                "    Args:\n",
                "        examples: Batch of examples with 'text' field\n",
                "        \n",
                "    Returns:\n",
                "        Tokenized examples\n",
                "    \"\"\"\n",
                "    return tokenizer(\n",
                "        examples['text'],\n",
                "        truncation=True,\n",
                "        max_length=config.max_seq_length,\n",
                "        padding=False  # Dynamic padding handled by data collator\n",
                "    )\n",
                "\n",
                "\n",
                "print(\"\\nTokenizing datasets...\")\n",
                "tokenized_datasets = dataset_dict.map(\n",
                "    tokenize_function,\n",
                "    batched=True,\n",
                "    desc=\"Tokenizing\"\n",
                ")\n",
                "\n",
                "# Remove columns that are not needed for training (keeps only model inputs + labels)\n",
                "columns_to_remove = ['text', 'label', 'Claim', 'Source']\n",
                "tokenized_datasets = tokenized_datasets.remove_columns(columns_to_remove)\n",
                "\n",
                "print(\"\\nTokenization complete!\")\n",
                "print(\"\\nColumns kept for training:\", tokenized_datasets['train'].column_names)\n",
                "print(tokenized_datasets)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Load Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Loading model: microsoft/deberta-v2-xlarge\n",
                        "This may take several minutes...\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Model loaded successfully!\n",
                        "\n",
                        "Model parameters: 886,972,428\n",
                        "Device: mps\n"
                    ]
                }
            ],
            "source": [
                "print(f\"\\nLoading model: {config.model_name}\")\n",
                "print(\"This may take several minutes...\\n\")\n",
                "\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\n",
                "    config.model_name,\n",
                "    num_labels=len(unique_labels),\n",
                "    id2label=id2label,\n",
                "    label2id=label2id,\n",
                "    problem_type=\"single_label_classification\"\n",
                ")\n",
                "\n",
                "# Move model to device\n",
                "model = model.to(device)\n",
                "# Disable gradient checkpointing\n",
                "model.gradient_checkpointing_disable()\n",
                "\n",
                "print(\"Model loaded successfully!\")\n",
                "print(f\"\\nModel parameters: {model.num_parameters():,}\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Define Focal Loss Trainer\n",
                "\n",
                "Custom trainer implementing Focal Loss with Gamma=4.\n",
                "\n",
                "**Focal Loss**: Addresses class imbalance by down-weighting easy examples.\n",
                "\n",
                "Formula: `FL(pt) = -(1 - pt)^γ * log(pt)`\n",
                "\n",
                "Where:\n",
                "- `pt` is the probability of the correct class\n",
                "- `γ` (gamma) controls the down-weighting factor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Focal Loss Trainer defined!\n",
                        "Gamma parameter: 4\n"
                    ]
                }
            ],
            "source": [
                "class FocalLossTrainer(Trainer):\n",
                "    \"\"\"\n",
                "    Custom Trainer with Focal Loss.\n",
                "    \n",
                "    Implements focal loss to handle class imbalance as per paper's findings.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self, focal_gamma: float = 4.0, *args, **kwargs):\n",
                "        super().__init__(*args, **kwargs)\n",
                "        self.focal_gamma = focal_gamma\n",
                "        print(f\"\\nUsing Focal Loss with Gamma = {self.focal_gamma}\")\n",
                "    \n",
                "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):  # Added num_items_in_batch\n",
                "        \"\"\"\n",
                "        Compute focal loss instead of standard cross-entropy.\n",
                "        \n",
                "        Args:\n",
                "            model: The model being trained\n",
                "            inputs: Input batch\n",
                "            return_outputs: Whether to return model outputs\n",
                "            \n",
                "        Returns:\n",
                "            Loss value (and outputs if requested)\n",
                "        \"\"\"\n",
                "        labels = inputs.pop(\"labels\")\n",
                "        \n",
                "        # Forward pass\n",
                "        outputs = model(**inputs)\n",
                "        logits = outputs.logits\n",
                "        \n",
                "        # Compute focal loss\n",
                "        ce_loss = F.cross_entropy(logits, labels, reduction='none')\n",
                "        pt = torch.exp(-ce_loss)  # Probability of true class\n",
                "        focal_loss = ((1 - pt) ** self.focal_gamma * ce_loss).mean()\n",
                "        \n",
                "        return (focal_loss, outputs) if return_outputs else focal_loss\n",
                "\n",
                "\n",
                "print(\"Focal Loss Trainer defined!\")\n",
                "print(f\"Gamma parameter: {config.focal_gamma}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Define Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Metrics function defined!\n"
                    ]
                }
            ],
            "source": [
                "def compute_metrics(eval_pred):\n",
                "    \"\"\"\n",
                "    Compute evaluation metrics.\n",
                "    \n",
                "    Args:\n",
                "        eval_pred: Tuple of (predictions, labels)\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary of metrics\n",
                "    \"\"\"\n",
                "    predictions, labels = eval_pred\n",
                "    predictions = np.argmax(predictions, axis=1)\n",
                "    \n",
                "    # Calculate metrics\n",
                "    accuracy = accuracy_score(labels, predictions)\n",
                "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
                "        labels, \n",
                "        predictions, \n",
                "        average='weighted',\n",
                "        zero_division=0\n",
                "    )\n",
                "    \n",
                "    return {\n",
                "        'accuracy': accuracy,\n",
                "        'precision': precision,\n",
                "        'recall': recall,\n",
                "        'f1': f1\n",
                "    }\n",
                "\n",
                "\n",
                "print(\"Metrics function defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: Setup Training Arguments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "TRAINING ARGUMENTS\n",
                        "======================================================================\n",
                        "\n",
                        "Output directory: ./output/deberta_flicc\n",
                        "\n",
                        "Training:\n",
                        "  Epochs: 15\n",
                        "  Batch size (per device): 1\n",
                        "  Gradient accumulation: 16\n",
                        "  Effective batch size: 16\n",
                        "  Learning rate: 1e-05\n",
                        "  Weight decay: 0.01\n",
                        "  Warmup ratio: 0.1\n",
                        "\n",
                        "Evaluation:\n",
                        "  Strategy: IntervalStrategy.EPOCH\n",
                        "  Metric for best model: f1\n",
                        "\n",
                        "Device: mps\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "# Create output directory\n",
                "Path(config.output_dir).mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Define training arguments\n",
                "training_args = TrainingArguments(\n",
                "    # Output\n",
                "    output_dir=config.output_dir,\n",
                "    \n",
                "    # Training hyperparameters\n",
                "    learning_rate=config.learning_rate,\n",
                "    weight_decay=config.weight_decay,\n",
                "    num_train_epochs=config.num_epochs,\n",
                "    per_device_train_batch_size=config.batch_size,\n",
                "    per_device_eval_batch_size=config.batch_size,\n",
                "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
                "    max_grad_norm=1.0,\n",
                "    \n",
                "    # Learning rate schedule\n",
                "    warmup_ratio=config.warmup_ratio,\n",
                "    lr_scheduler_type=\"cosine\",\n",
                "    \n",
                "    # Evaluation and saving\n",
                "    eval_strategy=config.evaluation_strategy,  # Changed from evaluation_strategy\n",
                "    save_strategy=config.save_strategy,\n",
                "    load_best_model_at_end=True,\n",
                "    metric_for_best_model=config.metric_for_best_model,\n",
                "    greater_is_better=True,\n",
                "    \n",
                "    # Logging\n",
                "    logging_dir=f\"{config.output_dir}/logs\",\n",
                "    logging_steps=config.logging_steps,\n",
                "    report_to=[\"tensorboard\"],\n",
                "    \n",
                "    # Device configuration\n",
                "    use_mps_device=(device.type == \"mps\"),\n",
                "    \n",
                "    # Reproducibility\n",
                "    seed=config.seed,\n",
                "    \n",
                "    # Memory optimization\n",
                "    fp16=False,  # MPS works better with FP32\n",
                "    gradient_checkpointing=False,  # Can enable if OOM\n",
                "    \n",
                "    # Save settings\n",
                "    save_total_limit=3,  # Keep only 3 best checkpoints\n",
                ")\n",
                "\n",
                "# Display training configuration\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TRAINING ARGUMENTS\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nOutput directory: {training_args.output_dir}\")\n",
                "print(f\"\\nTraining:\")\n",
                "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
                "print(f\"  Batch size (per device): {training_args.per_device_train_batch_size}\")\n",
                "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
                "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
                "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
                "print(f\"  Weight decay: {training_args.weight_decay}\")\n",
                "print(f\"  Warmup ratio: {training_args.warmup_ratio}\")\n",
                "print(f\"\\nEvaluation:\")\n",
                "print(f\"  Strategy: {training_args.eval_strategy}\")\n",
                "print(f\"  Metric for best model: {training_args.metric_for_best_model}\")\n",
                "print(f\"\\nDevice: {device}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Initialize Trainer and Start Training\n",
                "\n",
                "**Expected Duration**: Full fine-tuning of DeBERTa V2 XLarge for 15 epochs will take many hours (potentially 10-20 hours on Apple Silicon).\n",
                "\n",
                "The model will be evaluated after each epoch and the best model will be saved based on F1 score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Using Focal Loss with Gamma = 4\n",
                        "\n",
                        "======================================================================\n",
                        "STARTING TRAINING\n",
                        "======================================================================\n",
                        "\n",
                        "Model: microsoft/deberta-v2-xlarge\n",
                        "Training samples: 1,796\n",
                        "Validation samples: 457\n",
                        "\n",
                        "This will take many hours. Monitor the progress below.\n",
                        "\n",
                        "TensorBoard logs: ./output/deberta_flicc/logs\n",
                        "To view: tensorboard --logdir ./output/deberta_flicc/logs\n",
                        "\n",
                        "======================================================================\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='566' max='1695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [ 566/1695 51:23 < 1:42:53, 0.18 it/s, Epoch 5/15]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "      <th>Precision</th>\n",
                            "      <th>Recall</th>\n",
                            "      <th>F1</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>1.177300</td>\n",
                            "      <td>1.104082</td>\n",
                            "      <td>0.448578</td>\n",
                            "      <td>0.438608</td>\n",
                            "      <td>0.448578</td>\n",
                            "      <td>0.390099</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.553600</td>\n",
                            "      <td>0.511075</td>\n",
                            "      <td>0.691466</td>\n",
                            "      <td>0.723315</td>\n",
                            "      <td>0.691466</td>\n",
                            "      <td>0.691748</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.276100</td>\n",
                            "      <td>0.450313</td>\n",
                            "      <td>0.726477</td>\n",
                            "      <td>0.754069</td>\n",
                            "      <td>0.726477</td>\n",
                            "      <td>0.725310</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>0.154300</td>\n",
                            "      <td>0.535573</td>\n",
                            "      <td>0.715536</td>\n",
                            "      <td>0.759870</td>\n",
                            "      <td>0.715536</td>\n",
                            "      <td>0.720238</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>0.033900</td>\n",
                            "      <td>0.526338</td>\n",
                            "      <td>0.726477</td>\n",
                            "      <td>0.747029</td>\n",
                            "      <td>0.726477</td>\n",
                            "      <td>0.727389</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='457' max='457' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [457/457 00:32]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     torch.mps.empty_cache()\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/transformers/trainer.py:2790\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2787\u001b[39m     \u001b[38;5;28mself\u001b[39m.control.should_training_stop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2789\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_epoch_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2790\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[32m   2792\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DebugOption.TPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.debug:\n\u001b[32m   2795\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[32m   2796\u001b[39m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/transformers/trainer.py:3228\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3225\u001b[39m         \u001b[38;5;28mself\u001b[39m.control.should_save = is_new_best_metric\n\u001b[32m   3227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_save:\n\u001b[32m-> \u001b[39m\u001b[32m3228\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3229\u001b[39m     \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_save(\u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/transformers/trainer.py:3345\u001b[39m, in \u001b[36mTrainer._save_checkpoint\u001b[39m\u001b[34m(self, model, trial)\u001b[39m\n\u001b[32m   3341\u001b[39m         \u001b[38;5;28mself\u001b[39m.state.best_model_checkpoint = best_checkpoint_dir\n\u001b[32m   3343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_only_model:\n\u001b[32m   3344\u001b[39m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3345\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3346\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_scaler(output_dir)\n\u001b[32m   3347\u001b[39m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/transformers/trainer.py:3472\u001b[39m, in \u001b[36mTrainer._save_optimizer_and_scheduler\u001b[39m\u001b[34m(self, output_dir)\u001b[39m\n\u001b[32m   3467\u001b[39m     save_fsdp_optimizer(\n\u001b[32m   3468\u001b[39m         \u001b[38;5;28mself\u001b[39m.accelerator.state.fsdp_plugin, \u001b[38;5;28mself\u001b[39m.accelerator, \u001b[38;5;28mself\u001b[39m.optimizer, \u001b[38;5;28mself\u001b[39m.model, output_dir\n\u001b[32m   3469\u001b[39m     )\n\u001b[32m   3470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.should_save:\n\u001b[32m   3471\u001b[39m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3472\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3474\u001b[39m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[32m   3475\u001b[39m is_deepspeed_custom_scheduler = \u001b[38;5;28mself\u001b[39m.is_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3476\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[32m   3477\u001b[39m )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/torch/serialization.py:967\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/my_python_envs/lab_env/lib/python3.12/site-packages/torch/serialization.py:1268\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1266\u001b[39m         storage = storage.cpu()\n\u001b[32m   1267\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[31mKeyboardInterrupt\u001b[39m: "
                    ]
                }
            ],
            "source": [
                "# Data collator for dynamic padding\n",
                "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
                "\n",
                "# Initialize trainer\n",
                "trainer = FocalLossTrainer(\n",
                "    focal_gamma=config.focal_gamma,\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_datasets['train'],\n",
                "    eval_dataset=tokenized_datasets['validation'],\n",
                "    tokenizer=tokenizer,\n",
                "    data_collator=data_collator,\n",
                "    compute_metrics=compute_metrics,\n",
                "    callbacks=[EarlyStoppingCallback(early_stopping_patience=config.early_stopping_patience)]\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STARTING TRAINING\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nModel: {config.model_name}\")\n",
                "print(f\"Training samples: {len(tokenized_datasets['train']):,}\")\n",
                "print(f\"Validation samples: {len(tokenized_datasets['validation']):,}\")\n",
                "print(f\"\\nThis will take many hours. Monitor the progress below.\")\n",
                "print(f\"\\nTensorBoard logs: {config.output_dir}/logs\")\n",
                "print(f\"To view: tensorboard --logdir {config.output_dir}/logs\")\n",
                "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
                "\n",
                "# Clear MPS cache if available\n",
                "if torch.backends.mps.is_available():\n",
                "    torch.mps.empty_cache()\n",
                "# Start training\n",
                "train_result = trainer.train()\n",
                "\n",
                "# Save the final model\n",
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"TRAINING COMPLETE\")\n",
                "print(\"=\"*70)\n",
                "print(f\"\\nSaving final model to: {config.output_dir}/final_model\")\n",
                "trainer.save_model(f\"{config.output_dir}/final_model\")\n",
                "tokenizer.save_pretrained(f\"{config.output_dir}/final_model\")\n",
                "print(\"Model saved!\")\n",
                "\n",
                "# Display training metrics\n",
                "print(\"\\nTraining Metrics:\")\n",
                "print(f\"  Training Loss: {train_result.training_loss:.4f}\")\n",
                "print(f\"  Training Steps: {train_result.global_step}\")\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10.5: Export Best Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading best model from ./output/deberta_flicc/checkpoint-452...\n",
                        "Saving to ./best_model...\n",
                        "Success! You can now safely delete the 'output' folder.\n"
                    ]
                }
            ],
            "source": [
                "# 1. Point to your Epoch 3 checkpoint\n",
                "# Replace 'checkpoint-423' with the actual folder name for Epoch 3\n",
                "checkpoint_path = \"./output/deberta_flicc/checkpoint-452\" \n",
                "\n",
                "# 2. Load it\n",
                "print(f\"Loading best model from {checkpoint_path}...\")\n",
                "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
                "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, use_fast=False)\n",
                "\n",
                "# 3. Save it to a permanent location\n",
                "final_path = \"./best_model\"\n",
                "print(f\"Saving to {final_path}...\")\n",
                "model.save_pretrained(final_path)\n",
                "tokenizer.save_pretrained(final_path)\n",
                "\n",
                "print(\"Success! You can now safely delete the 'output' folder.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 11: Validation Set Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "VALIDATION SET EVALUATION\n",
                        "======================================================================\n",
                        "\n",
                        "Validation Results:\n",
                        "  eval_loss: 0.5263\n",
                        "  eval_accuracy: 0.7265\n",
                        "  eval_precision: 0.7470\n",
                        "  eval_recall: 0.7265\n",
                        "  eval_f1: 0.7274\n",
                        "\n",
                        "Detailed Classification Report (Validation):\n",
                        "                         precision    recall  f1-score   support\n",
                        "\n",
                        "             ad hominem       0.70      0.78      0.74        67\n",
                        "               anecdote       0.88      0.88      0.88        43\n",
                        "         cherry picking       0.59      0.79      0.68        56\n",
                        "      conspiracy theory       0.88      0.72      0.79        39\n",
                        "           fake experts       0.83      0.83      0.83        12\n",
                        "           false choice       0.43      0.77      0.56        13\n",
                        "      false equivalence       0.57      0.29      0.38        14\n",
                        "impossible expectations       0.63      0.73      0.68        37\n",
                        "      misrepresentation       0.75      0.63      0.69        38\n",
                        "     oversimplification       0.96      0.61      0.75        36\n",
                        "           single cause       0.81      0.77      0.79        57\n",
                        "     slothful induction       0.72      0.64      0.68        45\n",
                        "\n",
                        "               accuracy                           0.73       457\n",
                        "              macro avg       0.73      0.70      0.70       457\n",
                        "           weighted avg       0.75      0.73      0.73       457\n",
                        "\n",
                        "======================================================================\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"VALIDATION SET EVALUATION\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Evaluate on validation set\n",
                "val_results = trainer.evaluate(eval_dataset=tokenized_datasets['validation'])\n",
                "\n",
                "print(\"\\nValidation Results:\")\n",
                "for key, value in val_results.items():\n",
                "    if isinstance(value, float):\n",
                "        print(f\"  {key}: {value:.4f}\")\n",
                "    else:\n",
                "        print(f\"  {key}: {value}\")\n",
                "\n",
                "# Get predictions for detailed analysis\n",
                "val_predictions = trainer.predict(tokenized_datasets['validation'])\n",
                "val_preds = np.argmax(val_predictions.predictions, axis=1)\n",
                "val_labels = val_predictions.label_ids\n",
                "\n",
                "# Print classification report\n",
                "print(\"\\nDetailed Classification Report (Validation):\")\n",
                "print(classification_report(\n",
                "    val_labels,\n",
                "    val_preds,\n",
                "    target_names=[id2label[i] for i in range(len(id2label))],\n",
                "    zero_division=0\n",
                "))\n",
                "\n",
                "print(\"=\"*70)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training Complete!\n",
                "\n",
                "### Summary\n",
                "\n",
                "DeBERTa V2 XLarge has been successfully fine-tuned with Focal Loss (Gamma=4) for fallacy detection.\n",
                "\n",
                "### Output Files\n",
                "\n",
                "Located in `./output/deberta_flicc/`:\n",
                "- `best_model/` - Fine-tuned model and tokenizer\n",
                "- `training_report.json` - Complete training report\n",
                "- `logs/` - TensorBoard logs\n",
                "- Checkpoint directories for model checkpoints\n",
                "\n",
                "### Performance Metrics\n",
                "\n",
                "- **Validation Results**: See Step 11\n",
                "- **Test Results**: See -> evaluate_model.ipynb\n",
                "\n",
                "### Next Steps\n",
                "\n",
                "1.Run the demo/ artefact in Terminal -> `python fallacy_detector_tui.py`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lab_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
